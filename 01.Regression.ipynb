{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55381b0b-430c-4fc1-aa07-4c4a402ebbf6",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c759e-6d80-4768-809e-684458c371ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple Linear Regression:\n",
    "\n",
    "->Simple linear regression is a statistical method used to model the relationship between a single independent \n",
    "  variable (predictor) and a dependent variable (response).\n",
    "->It assumes that there is a linear relationship between the independent variable and the dependent variable.\n",
    "->The mathematical equation for simple linear regression is often represented as: Y = a + bX, where Y is the \n",
    "  dependent variable, X is the independent variable, a is the intercept, and b is the slope.\n",
    "->Simple linear regression is appropriate when you want to predict or understand the impact of one variable on\n",
    "  another, assuming a linear relationship.\n",
    "\n",
    "\n",
    "Example of Simple Linear Regression:\n",
    "Suppose you want to predict a person's weight (Y) based on their height (X). You collect data from a sample of \n",
    "individuals, where X represents their height in inches and Y represents their weight in pounds. You can use simple\n",
    "linear regression to model this relationship and estimate the equation: \n",
    "Weight = a + b * Height.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Multiple Linear Regression:\n",
    "\n",
    "->Multiple linear regression extends the concept of linear regression to model the relationship between a dependent \n",
    "  variable and two or more independent variables.\n",
    "->It assumes that there is a linear relationship between the dependent variable and each of the independent variables.\n",
    "->The mathematical equation for multiple linear regression can be represented as: Y = a + b₁X₁ + b₂X₂ + ... + bₙXₙ, \n",
    "  where Y is the dependent variable, X₁, X₂, ..., Xₙ are the independent variables, a is the intercept, and b₁, b₂,\n",
    "  ..., bₙ are the slopes associated with each independent variable.\n",
    "->Multiple linear regression is appropriate when you want to predict or understand the impact of multiple independent\n",
    "  variables on a single dependent variable.\n",
    "\n",
    "\n",
    "Example of Multiple Linear Regression:\n",
    "Suppose you want to predict a house's price (Y) based on several features, including its size in square feet (X₁), the \n",
    "number of bedrooms (X₂), and the distance to the nearest public transportation (X₃). You collect data on various houses\n",
    "and use multiple linear regression to model the relationship and estimate the equation: \n",
    "Price = a + b₁ * Size + b₂ * Bedrooms + b₃ * Distance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb852b-f4a8-4ff2-b022-b0dfe33092ba",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7212b-b89e-4b9a-a7bb-d99d068ec9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "->Linearity: Ensure a linear relationship between variables using scatterplots.\n",
    "\n",
    "->Independence of Errors: Check for patterns in residuals over time or with independent variables.\n",
    "\n",
    "->Homoscedasticity: Verify constant variance of residuals by plotting them against predictions.\n",
    "\n",
    "->Normality of Residuals: Examine residuals with histograms or Q-Q plots against a normal distribution.\n",
    "\n",
    "->Independence of Observations: Ensure no patterns or dependencies among data points.\n",
    "\n",
    "->No Multicollinearity: Check for high correlation between independent variables using correlation coefficients or VIFs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10673f12-9625-4dc4-9baa-d186a725f8ea",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63e314-774a-4c15-bf5c-a2eba782a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Intercept: \n",
    "It's the starting point of the regression line, representing the expected value of the dependent variable when all\n",
    "independent variables are zero.\n",
    "\n",
    "Slope: \n",
    "It shows the change in the dependent variable for a one-unit change in the independent variable, while holding all \n",
    "other variables constant. It indicates the direction and strength of the relationship between the variables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d1a80-9273-439a-9ef7-656a86160b35",
   "metadata": {},
   "source": [
    "Explain the concept of gradient descent. How is it used in machine learning?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f3e8c-3791-4e29-a373-43d5b7fad1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient descent is an iterative optimization algorithm used in machine learning to find the best parameters\n",
    "(weights and biases) for a model by minimizing a cost function. It does this by repeatedly adjusting the parameters\n",
    "in the direction of steepest decrease (negative gradient) until it reaches a minimum, leading to improved model \n",
    "accuracy and performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a862a-5ec0-4a31-9240-3a9d81cf0a61",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9dbdd-27ae-46d4-9d1b-1cfe41b8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multiple linear regression is an extension of simple linear regression, allowing for the modeling of the relationship\n",
    "between a dependent variable and multiple independent variables. It's more complex, with an equation that includes \n",
    "several independent variables and their coefficients, making it suitable for situations where multiple factors influence\n",
    "the dependent variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2f2b1-de9d-4d03-8ea2-7c61d8f253a6",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4f4c0-0ee5-48f6-ae4b-9da492ea195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multicollinearity in multiple linear regression happens when independent variables are highly correlated, making it hard \n",
    "to interpret and estimate their individual effects. Detect it with correlation analysis or VIF, and address it by removing \n",
    "variables, combining them, using regularization, PCA, or feature selection.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57153bc6-87b8-481f-91de-0112537662eb",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d5117-d498-4cf4-a011-afc9e0f717be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Polynomial regression allows for nonlinear relationships between variables by introducing polynomial terms, such as \n",
    "X² and X³, in the regression equation. This is different from linear regression, which assumes a linear relationship with \n",
    "straight-line patterns. Polynomial regression is more flexible and can capture curved or nonlinear data patterns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d3173-9477-44ad-ada2-702ed9d97fac",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdda897-bed9-4b05-89a4-89e24c0c581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Advantages of Polynomial Regression:\n",
    "->Flexibility to capture nonlinear relationships.\n",
    "->Improved fit to data with curves and bends.\n",
    "->Higher accuracy when linear regression is inadequate.\n",
    "\n",
    "\n",
    "Disadvantages of Polynomial Regression:\n",
    "->Prone to overfitting with high-degree polynomials.\n",
    "->Increased model complexity.\n",
    "->Limited reliability for extrapolation.\n",
    "\n",
    "\n",
    "\n",
    "Use Polynomial Regression When:\n",
    "->Dealing with nonlinear data patterns.\n",
    "->Complexity in data requires a better fit.\n",
    "->Improved predictive accuracy is the goal.\n",
    "->Data is limited, and more complex models aren't feasible.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
